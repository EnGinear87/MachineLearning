---
title: "M7_Data Assignment"
author: "Melvin Wayne Abraham"
date: "3/3/2021"
output:
  word_document: default
  pdf_document: default
---
### Objective: 
"Apply boosting, bagging, and random forests to the insurance data set of your choice. Be sure to fit the models on a training set and to evaluate their performance on a test set (i.e., split the training set into a training and test set). How accurate are the results compared to simple methods like linear or logistic regression? Which of these approaches yields the best performance? Apply your champion models to the test data set for both the “TARGET_FLAG” and “TARGET_AMT” variables.

Download and use the following data sets for this assignment:

Logit Insurance: Training
Logit Insurance: TestPreview the document
Logit Insurance: RandomPreview the document"

## 1: Setup and Deliverables

```{r Clean Rstudio Environment and Import data from Excel}
#Clean Rstudio Console, Environment & Plots, Add libraries & Import data from Excel
cat("\014")
rm(list = ls())
graphics.off()

library(dplyr)
library(ggstatsplot)
library(ggplot2)
library(tidyverse)
library(MASS)
library(corrplot)
library(zoo)
library(caret)
library(psych)
library(InformationValue)
library(tree)
library(ISLR)
library(MASS)
library(randomForest)
library(gbm)


setwd("C:/Users/Melvin/Documents/William and Mary/Courses/Spring 2021/BUAD 5122 Machine Learning I/Module 7")
data <- read.csv("buad5122-m7-insurance-training.csv")
test <- read.csv("buad5122-m7-insurance-test.csv")


```

## 2: Data Parameters for since we have a mix of numerical and categorical and verify with a str and summary:

```{r, Creating values for dataframes}

data$INDEX <- as.factor(data$INDEX)
data$TARGET_FLAG <- as.factor(data$TARGET_FLAG)
data$SEX <- as.factor(data$SEX)
data$EDUCATION <- as.factor(data$EDUCATION)
data$PARENT1 <- as.factor(data$PARENT1)
data$INCOME <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data$INCOME)))

data$HOME_VAL <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data$HOME_VAL)))
data$MSTATUS <- as.factor(data$MSTATUS)
data$REVOKED <- as.factor(data$REVOKED)
data$RED_CAR <- as.factor(ifelse(data$RED_CAR=="yes", 1, 0))
data$URBANICITY <- ifelse(data$URBANICITY == "Highly Urban/ Urban", "Urban", "Rural")
data$URBANICITY <- as.factor(data$URBANICITY)
data$JOB <- as.factor(data$JOB)
data$CAR_USE <- as.factor(data$CAR_USE)
data$CAR_TYPE <- as.factor(data$CAR_TYPE)
data$DO_KIDS_DRIVE <- as.factor(ifelse(data$KIDSDRIV > 0, 1, 0 ))
data$OLDCLAIM <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data$OLDCLAIM)))
data$BLUEBOOK <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data$BLUEBOOK)))

summary(data)
str(data)


######## Same treatment on test data set ###########################

### Need to make sure our data is understood correctly by R, since we have a mix of numerical and categorical
test$INDEX <- as.factor(test$INDEX)
test$TARGET_FLAG <- as.factor(test$TARGET_FLAG)
test$SEX <- as.factor(test$SEX)
test$EDUCATION <- as.factor(test$EDUCATION)
test$PARENT1 <- as.factor(test$PARENT1)
test$INCOME <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", test$INCOME)))
test$HOME_VAL <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", test$HOME_VAL)))
test$MSTATUS <- as.factor(test$MSTATUS)
test$REVOKED <- as.factor(test$REVOKED)
test$RED_CAR <- as.factor(ifelse(test$RED_CAR=="yes", 1, 0))
test$URBANICITY <- ifelse(test$URBANICITY == "Highly Urban/ Urban", "Urban", "Rural")
test$URBANICITY <- as.factor(test$URBANICITY)
test$JOB <- as.factor(test$JOB)
test$CAR_USE <- as.factor(test$CAR_USE)
test$CAR_TYPE <- as.factor(test$CAR_TYPE)
test$DO_KIDS_DRIVE <- as.factor(ifelse(test$KIDSDRIV > 0, 1, 0 ))
test$OLDCLAIM <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", test$OLDCLAIM)))
test$BLUEBOOK <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", test$BLUEBOOK)))

summary(test)
str(test)

```


## 3: Data Exploration 

```{r, Find trends, outliers and describe graphing trends}
# Histograms for Numeric Variables
par(mfrow=c(2,2))
hist(data$AGE, col = "red", xlab = "Age", main = "AGE Hist")
data0<- subset(data, TARGET_FLAG == 1 )
boxplot(data$AGE, col = "red", main = "AGE BoxPlot")
hist(data0$AGE, col = "yellow", main = "AGE0 Hist")
boxplot(data0$AGE, col = "yellow", main = "AGEO BoxPlot")
par(mfrow=c(1,1))

par(mfrow=c(2,2))
hist(sqrt(data$TRAVTIME), col = "green", xlab = "SQRT TRAVTIME", main = "SQRT TRAVTIME Hist")
hist(data$YOJ, col = "blue", xlab = "YOJ", main = "YOJ Hist")
boxplot(sqrt(data$TRAVTIME), col = "green", main = "SQRT TRAVTIME BoxPlot")
boxplot(data$YOJ, col = "blue", main = "YOJ BoxPlot")
par(mfrow=c(1,1))

par(mfrow=c(2,2))
hist(sqrt(data$BLUEBOOK), col = "green", xlab = "SQRT BLUEBOOK", main = "SQRT BLUEBOOK Hist")
hist((data$TIF), col = "blue", xlab = "TIF", main = "TIF Hist")
boxplot(sqrt(data$BLUEBOOK), col = "green", main = "SQRT BLUEBOOK BoxPlot")
boxplot(data$TIF, col = "blue", main = "TIF BoxPlot")
par(mfrow=c(1,1))

par(mfrow=c(2,2))
hist(data$MVR_PTS, col = "red", xlab = "MVR_PTS", main = "MVR_PTS Hist")
hist(data$CAR_AGE, col = "blue", xlab = "CAR_AGE", main = "CAR_AGE Hist")
boxplot(data$MVR_PTS, col = "red", main = "MVR_PTS BoxPlot")
boxplot(data$CAR_AGE, col = "blue", xlab = "CAR_AGE", main = "CAR_AGE BoxPlot")
par(mfrow=c(1,1))

```

## 4: Data Transformation


```{r, "Fix NA's, note Car Age & Income Value was changed"}
#Training Dataset
data$AGE[is.na(data$AGE)] <- mean(data$AGE, na.rm = TRUE)

options(scipen = 4)

#Years on Job Input and Replacements for NA's and outliers
data$FlagYOJ = ifelse(is.na(data$YOJ),1,0)
data$YOJ[is.na(data$YOJ)] = median(data$YOJ, na.rm = TRUE)
upperWhisker = quantile(data$YOJ,c(.75))+1.5*(quantile(data$YOJ,c(.75))-quantile(data$YOJ,c(.25)))
lowerWhisker = quantile(data$YOJ,c(.25))-1.5*(quantile(data$YOJ,c(.75))-quantile(data$YOJ,c(.25)))

data$FlagYOJ = ifelse(data$YOJ <= lowerWhisker, 2, data$FlagYOJ)
data$FlagYOJ = ifelse(data$YOJ >= upperWhisker, 3, data$FlagYOJ)
data$YOJ = ifelse(data$YOJ==2, lowerWhisker, data$YOJ)
data$YOJ = ifelse(data$YOJ==3, upperWhisker, data$YOJ)

boxplot(data$YOJ, main = "Years on Job Update")
plot(data$YOJ, main = "Years on Job Quantile Function")

data$YOJ <- na.aggregate(data$YOJ, data$JOB, mean, na.rm = TRUE)

#Income Input and Replacements for NA's and outliers
data$FlagIncome = ifelse(is.na(data$INCOME),1,0)
data$INCOME[is.na(data$INCOME)] = median(data$INCOME, na.rm = TRUE)
upperWhisker = quantile(data$INCOME,c(.75))+1.5*(quantile(data$INCOME,c(.90))-quantile(data$INCOME,c(.10)))
lowerWhisker = quantile(data$INCOME,c(.25))-1.5*(quantile(data$INCOME,c(.90))-quantile(data$INCOME,c(.10)))

data$FlagIncome = ifelse(data$INCOME <= lowerWhisker, 2, data$FlagIncome)
data$FlagIncome = ifelse(data$INCOME >= upperWhisker, 3, data$FlagIncome)
data$INCOME = ifelse(data$INCOME==2, lowerWhisker, data$INCOME)
data$INCOME = ifelse(data$INCOME==3, upperWhisker, data$INCOME)

boxplot(data$INCOME, main = "Income Update")
plot(data$INCOME, main = "Income Quantile Function")

data$INCOME <- na.aggregate(data$INCOME, data$JOB, mean, na.rm = TRUE)

#summary(data$INCOME)

#Home_Val Input and Replacements for NA's and outliers
data$FlagHome_Val = ifelse(is.na(data$HOME_VAL),1,0)
data$HOME_VAL[is.na(data$HOME_VAL)] = median(data$HOME_VAL, na.rm = TRUE)
upperWhisker = quantile(data$HOME_VAL,c(.75))+1.5*(quantile(data$HOME_VAL,c(.75))-quantile(data$HOME_VAL,c(.25)))
lowerWhisker = quantile(data$HOME_VAL,c(.25))-1.5*(quantile(data$HOME_VAL,c(.75))-quantile(data$HOME_VAL,c(.25)))

data$FlagHome_Val = ifelse(data$HOME_VAL <= lowerWhisker, 2, data$FlagHome_Val)
data$FlagHome_Val = ifelse(data$HOME_VAL >= upperWhisker, 3, data$FlagHome_Val)
data$HOME_VAL = ifelse(data$HOME_VAL==2, lowerWhisker, data$HOME_VAL)
data$HOME_VAL = ifelse(data$HOME_VAL==3, upperWhisker, data$HOME_VAL)

boxplot(data$HOME_VAL, main = "Home Value Update")
plot(data$HOME_VAL, main = "Home Value Quantile Function")

data$HOME_VAL <- na.aggregate(data$HOME_VAL, data$JOB, mean, na.rm = TRUE )

#summary(data$HOME_VAL)

#Car_Age Input and Replacements for NA's and outliers (maybe divided this by 12 because of months per year)
data$FlagCar_Age = ifelse(is.na(data$CAR_AGE),1,0)
data$CAR_AGE[data$CAR_AGE < 0] = median(data$CAR_AGE)
data$CAR_AGE[is.na(data$CAR_AGE)] = median(data$CAR_AGE, na.rm = TRUE)
upperWhisker = quantile(data$CAR_AGE,c(.75))+1.5*(quantile(data$CAR_AGE,c(.75))-quantile(data$CAR_AGE,c(.25)))
lowerWhisker = quantile(data$CAR_AGE,c(.25))-1.5*(quantile(data$CAR_AGE,c(.75))-quantile(data$CAR_AGE,c(.25)))

data$FlagCar_Age = ifelse(data$CAR_AGE <= lowerWhisker, 2, data$FlagCar_Age)
data$FlagCar_Age = ifelse(data$CAR_AGE >= upperWhisker, 3, data$FlagCar_Age)
data$CAR_AGE = ifelse(data$CAR_AGE==2, lowerWhisker, data$CAR_AGE)
data$CAR_AGE = ifelse(data$CAR_AGE==3, upperWhisker, data$CAR_AGE)

boxplot(data$CAR_AGE, main = "Car_Age Update")
plot(data$CAR_AGE, main = "Car_Age Quantile Function")
data$CAR_AGE <- na.aggregate(data$CAR_AGE, data$CAR_TYPE, mean, na.rm = TRUE)
data$CAR_AGE[data$CAR_AGE < 0 ] <- 0

#Old Claim Input and Replacements for NA's and outliers (EVALUATE THIS AREA AGAIN)
data$FlagOldClaim= ifelse(is.na(data$OLDCLAIM),1,0)
data$OLDCLAIM[is.na(data$OLDCLAIM)] = 1/max(data$OLDCLAIM, na.rm = TRUE)
upperWhisker = quantile(data$OLDCLAIM,c(.75))+1.5*(quantile(data$OLDCLAIM,c(.75))-quantile(data$OLDCLAIM,c(.25)))
lowerWhisker = quantile(data$OLDCLAIM,c(.25))-1.5*(quantile(data$OLDCLAIM,c(.75))-quantile(data$OLDCLAIM,c(.25)))

data$FlagOldClaim = ifelse(data$OLDCLAIM <= lowerWhisker, 2, data$FlagOldClaim)
data$FlagOldClaim = ifelse(data$OLDCLAIM >= upperWhisker, 3, data$FlagOldClaim)
data$OLDCLAIM = ifelse(data$OLDCLAIM==2, lowerWhisker, data$OLDCLAIM)
data$OLDCLAIM = ifelse(data$OLDCLAIM==3, upperWhisker, data$OLDCLAIM)

boxplot(data$OLDCLAIM, main = "Old Claim Update")
plot(data$OLDCLAIM, main = "Old Claim Quantile Function")

data$OLDCLAIM <- ifelse(data$CAR_AGE < 11 & !is.na(data$CAR_AGE),0,data$OLDCLAIM)
data$OLDCLAIM <- na.aggregate(data$OLDCLAIM, data$CAR_AGE, mean, na.rm = TRUE )
data$HOME_OWNER <- ifelse(data$HOME_VAL == 0, 0, 1)
data$SQRT_TRAVTIME <- sqrt(data$TRAVTIME)

#Bluebook Input and Replacements for NA's and outliers
data$FlagBluebook = ifelse(is.na(data$BLUEBOOK),1,0)
data$BLUEBOOK[is.na(data$BLUEBOOK)] = median(data$BLUEBOOK, na.rm = TRUE)
upperWhisker = quantile(data$BLUEBOOK,c(.75))+1.5*(quantile(data$BLUEBOOK,c(.75))-quantile(data$BLUEBOOK,c(.25)))
lowerWhisker = quantile(data$BLUEBOOK,c(.25))-1.5*(quantile(data$BLUEBOOK,c(.75))-quantile(data$BLUEBOOK,c(.25)))

data$FlagBluebook = ifelse(data$BLUEBOOK <= lowerWhisker, 2, data$FlagBluebook)
data$FlagBluebook = ifelse(data$BLUEBOOK >= upperWhisker, 3, data$FlagBluebook)
data$BLUEBOOK = ifelse(data$BLUEBOOK==2, lowerWhisker, data$BLUEBOOK)
data$BLUEBOOK = ifelse(data$BLUEBOOK==3, upperWhisker, data$BLUEBOOK)

boxplot(data$BLUEBOOK, main = "Bluebook Update")
plot(data$BLUEBOOK, main = "Bluebook Quantile Function")
data$SQRT_BLUEBOOK <- sqrt(data$BLUEBOOK)


# Bin Income Change income value (UPDATED INCOME FACTORS)
data$INCOME_bin[is.na(data$INCOME)] <- "NA"
data$INCOME_bin[data$INCOME == 0] <- "Zero"
data$INCOME_bin[data$INCOME >= 1 & data$INCOME < 12500] <- "Low"
data$INCOME_bin[data$INCOME >= 12500 & data$INCOME < 70000] <- "Medium"
data$INCOME_bin[data$INCOME >= 70000 & data$INCOME < 120000] <- "High"
data$INCOME_bin[data$INCOME >= 120000] <- "Very High"
data$INCOME_bin <- factor(data$INCOME_bin)
data$INCOME_bin <- factor(data$INCOME_bin, levels=c("NA","Zero","Low","Medium","High", "Very High"))

#Bin Home Value (NEWLY ADDED VALUE)
data$HOME_VAL_bin[is.na(data$HOME_VAL)] <- "NA"
data$HOME_VAL_bin[data$HOME_VAL == 0] <- "Zero"
data$HOME_VAL_bin[data$HOME_VAL >= 1 & data$HOME_VAL < 150000] = "Low"
data$HOME_VAL_bin[data$HOME_VAL >= 150000 & data$HOME_VAL < 300000] = "Medium"
data$HOME_VAL_bin[data$HOME_VAL >= 300000 & data$HOME_VAL < 500000] <- "High"
data$HOME_VAL_bin[data$HOME_VAL >= 500000] <- "Very High"
data$HOME_VAL_bin <- factor(data$HOME_VAL_bin)
data$HOME_VAL_bin <- factor(data$HOME_VAL_bin, levels =c("NA", "Zero", "Low", "Medium", "High", "Very High"))

#Bin Job (NEWLY ADDED VALUE)
#data$JOB_bin[is.na(data$JOB)] = "NA"
data$JOB_bin[data$JOB == ""] = "NA"
data$JOB_bin[data$JOB == "Doctor"] = "Doctor"
data$JOB_bin[data$JOB == "Home Maker"] = "Home Maker"
data$JOB_bin[data$JOB == "Professional"] = "Professional"
data$JOB_bin[data$JOB == "Student"] = "Student"
data$JOB_bin[data$JOB == "Lawyer"] = "Lawyer"
data$JOB_bin[data$JOB == "z_Blue Collar"] = "Blue Collar"
data$JOB_bin[data$JOB == "Clerical"] = "Clerical"
data$JOB_bin[data$JOB == "Manager"] = "Manager"
data$JOB_bin = factor(data$JOB_bin)
data$JOB_bin <- factor(data$JOB_bin, levels = c("NA", "Doctor", "Home Maker", "Professional", "Student", "Lawyer", "Blue Collar",
                       "Clerical", "Manager"))

#Bin Education (NEWLY ADDED VALUE)
#summary(data$EDUCATION_bin)
#head(data$EDUCATION_bin)

data$EDUCATION_bin[data$EDUCATION == ""] = "NA"
data$EDUCATION_bin[data$EDUCATION == "<High School"] = "Still in High School"
data$EDUCATION_bin[data$EDUCATION == "z_High School"] = "Finished High School"
data$EDUCATION_bin[data$EDUCATION == "Bachelors"] = "Bachelors"
data$EDUCATION_bin[data$EDUCATION == "Masters"] = "Masters"
data$EDUCATION_bin[data$EDUCATION == "PhD"] = "PhD"
data$EDUCATION_bin = factor(data$EDUCATION_bin)
data$EDUCATION_bin = factor(data$EDUCATION_bin, levels = c("NA", "Still in High School", "Finished High School", "Bachelors",
                                                           "Masters", "PhD" ))

#Bin Sex (NEWLY ADDED VALUE)
data$FlagFemaleSex = as.factor(ifelse(data$SEX == "z_F", 1, 0))
data$FlagMaleSex = as.factor(ifelse(data$SEX == "M", 1, 0))

#Test Dataset
test$AGE[is.na(test$AGE)] <- mean(test$AGE, na.rm = TRUE)

#Years on Job Test Input and Replacements for NA's and outliers
test$FlagYOJ = ifelse(is.na(test$YOJ),1,0)
test$YOJ[is.na(test$YOJ)] = median(test$YOJ, na.rm = TRUE)
upperWhisker = quantile(test$YOJ,c(.75))+1.5*(quantile(test$YOJ,c(.75))-quantile(test$YOJ,c(.25)))
lowerWhisker = quantile(test$YOJ,c(.25))-1.5*(quantile(test$YOJ,c(.75))-quantile(test$YOJ,c(.25)))

test$FlagYOJ = ifelse(test$YOJ <= lowerWhisker, 2, test$FlagYOJ)
test$FlagYOJ = ifelse(test$YOJ >= upperWhisker, 3, test$FlagYOJ)
test$YOJ = ifelse(test$YOJ==2, lowerWhisker, test$YOJ)
test$YOJ = ifelse(test$YOJ==3, upperWhisker, test$YOJ)

boxplot(test$YOJ, main = "Test Years on Job Update")
plot(test$YOJ, main = "Test Years on Job Quantile Function")

test$YOJ <- na.aggregate(test$YOJ, test$JOB, mean, na.rm = TRUE)

#Income Test Input and Replacements for NA's and outliers
test$FlagIncome = ifelse(is.na(test$INCOME),1,0)
test$INCOME[is.na(test$INCOME)] = median(test$INCOME, na.rm = TRUE)
upperWhisker = quantile(test$INCOME,c(.75))+1.5*(quantile(test$INCOME,c(.75))-quantile(test$INCOME,c(.25)))
lowerWhisker = quantile(test$INCOME,c(.25))-1.5*(quantile(test$INCOME,c(.75))-quantile(test$INCOME,c(.25)))

test$FlagIncome = ifelse(test$INCOME <= lowerWhisker, 2, test$FlagIncome)
test$FlagIncome = ifelse(test$INCOME >= upperWhisker, 3, test$FlagIncome)
test$INCOME = ifelse(test$INCOME==2, lowerWhisker, test$INCOME)
test$INCOME = ifelse(test$INCOME==3, upperWhisker, test$INCOME)

boxplot(test$INCOME, main = "Income Update")
plot(data$INCOME, main = "Income Quantile Function")
test$INCOME <- na.aggregate(test$INCOME, test$JOB, mean, na.rm = TRUE)

#Home_Val Test Input and Replacements48 for NA's and outliers
test$FlagHome_Val = ifelse(is.na(test$HOME_VAL),1,0)
test$HOME_VAL[is.na(test$HOME_VAL)] = median(test$HOME_VAL, na.rm = TRUE)
upperWhisker = quantile(test$HOME_VAL,c(.75))+1.5*(quantile(test$HOME_VAL,c(.75))-quantile(test$HOME_VAL,c(.25)))
lowerWhisker = quantile(test$HOME_VAL,c(.25))-1.5*(quantile(test$HOME_VAL,c(.75))-quantile(test$HOME_VAL,c(.25)))

test$FlagHome_Val = ifelse(test$HOME_VAL <= lowerWhisker, 2, test$FlagHome_Val)
test$FlagHome_Val = ifelse(test$HOME_VAL >= upperWhisker, 3, test$FlagHome_Val)
test$HOME_VAL = ifelse(test$HOME_VAL==2, lowerWhisker, test$HOME_VAL)
test$HOME_VAL = ifelse(test$HOME_VAL==3, upperWhisker, test$HOME_VAL)

boxplot(test$HOME_VAL, main = "Test Home Value Update")
plot(test$HOME_VAL, main = "Test Home Value Quantile Function")
test$HOME_VAL <- na.aggregate(test$HOME_VAL, test$JOB, mean, na.rm = TRUE )

test$CAR_AGE <- na.aggregate(test$CAR_AGE, test$CAR_TYPE, mean, na.rm = TRUE)
test$CAR_AGE[test$CAR_AGE < 0 ] <- 0 
test$OLDCLAIM <- ifelse(test$CAR_AGE < 11 & !is.na(test$CAR_AGE),0,test$OLDCLAIM)
test$OLDCLAIM <- na.aggregate(test$OLDCLAIM, test$CAR_AGE, mean, na.rm = TRUE )
test$HOME_OWNER <- ifelse(test$HOME_VAL == 0, 0, 1)
test$SQRT_TRAVTIME <- sqrt(test$TRAVTIME)
test$SQRT_BLUEBOOK <- sqrt(test$BLUEBOOK)

# Bin Income Test
#test$INCOME_bin[is.na(test$INCOME)] <- "NA"
#test$INCOME_bin[test$INCOME == 0] <- "Zero"
#test$INCOME_bin[test$INCOME >= 1 & test$INCOME < 28299] <- "Low"
#test$INCOME_bin[test$INCOME >= 28299 & test$INCOME < 86268] <- "Medium"
#test$INCOME_bin[test$INCOME >= 86268] <- "High"

#test$INCOME_bin <- factor(test$INCOME_bin)
#test$INCOME_bin <- factor(test$INCOME_bin, levels=c("NA","Zero","Low","Medium","High"))

test$INCOME_bin[is.na(test$INCOME)] <- "NA"
test$INCOME_bin[test$INCOME == 0] <- "Zero"
test$INCOME_bin[test$INCOME >= 1 & test$INCOME < 12500] <- "Low"
test$INCOME_bin[test$INCOME >= 12500 & test$INCOME < 70000] <- "Medium"
test$INCOME_bin[test$INCOME >= 70000 & test$INCOME < 120000] <- "High"
test$INCOME_bin[test$INCOME >= 120000] <- "Very High"
test$INCOME_bin <- factor(test$INCOME_bin)
test$INCOME_bin <- factor(test$INCOME_bin, levels=c("NA","Zero","Low","Medium","High", "Very High"))


#Bin Home Value Test (NEWLY ADDED VALUE)
test$HOME_VAL_bin[is.na(test$HOME_VAL)] <- "NA"
test$HOME_VAL_bin[test$HOME_VAL == 0] <- "Zero"
test$HOME_VAL_bin[test$HOME_VAL >= 1 & test$HOME_VAL < 150000] = "Low"
test$HOME_VAL_bin[test$HOME_VAL >= 150000 & test$HOME_VAL < 300000] = "Medium"
test$HOME_VAL_bin[test$HOME_VAL >= 300000 & test$HOME_VAL < 500000] <- "High"
test$HOME_VAL_bin[test$HOME_VAL >= 500000] <- "Very High"
test$HOME_VAL_bin <- factor(test$HOME_VAL_bin)
test$HOME_VAL_bin <- factor(test$HOME_VAL_bin, levels =c("NA", "Zero", "Low", "Medium", "High", "Very High"))

#Bin Job Test (NEWLY ADDED VALUE)
#test$JOB_bin[is.na(test$JOB)] = "NA"
test$JOB_bin[test$JOB == ""] = "NA"
test$JOB_bin[test$JOB == "Doctor"] = "Doctor"
test$JOB_bin[test$JOB == "Home Maker"] = "Home Maker"
test$JOB_bin[test$JOB == "Professional"] = "Professional"
test$JOB_bin[test$JOB == "Student"] = "Student"
test$JOB_bin[test$JOB == "Lawyer"] = "Lawyer"
test$JOB_bin[test$JOB == "z_Blue Collar"] = "Blue Collar"
test$JOB_bin[test$JOB == "Clerical"] = "Clerical"
test$JOB_bin[test$JOB == "Manager"] = "Manager"
test$JOB_bin = factor(test$JOB_bin)
test$JOB_bin <- factor(test$JOB_bin, levels = c("NA", "Doctor", "Home Maker", "Professional", "Student", "Lawyer", "Blue Collar",
                                                "Clerical", "Manager"))

#Bin Education Test (NEWLY ADDED VALUE)
#summary(test$EDUCATION_bin)
#head(test$EDUCATION_bin)

test$EDUCATION_bin[test$EDUCATION == ""] = "NA"
test$EDUCATION_bin[test$EDUCATION == "<High School"] = "Still in High School"
test$EDUCATION_bin[test$EDUCATION == "z_High School"] = "Finished High School"
test$EDUCATION_bin[test$EDUCATION == "Bachelors"] = "Bachelors"
test$EDUCATION_bin[test$EDUCATION == "Masters"] = "Masters"
test$EDUCATION_bin[test$EDUCATION == "PhD"] = "PhD"
test$EDUCATION_bin = factor(test$EDUCATION_bin)
test$EDUCATION_bin = factor(test$EDUCATION_bin, levels = c("NA", "Still in High School", "Finished High School", "Bachelors",
                                                           "Masters", "PhD" ))

#Bin Sex Test (NEWLY ADDED VALUE)
test$FlagFemaleSex = as.factor(ifelse(test$SEX == "z_F", 1, 0))
test$FlagMaleSex = as.factor(ifelse(test$SEX == "M", 1, 0))

summary(data)
summary(test)


numeric <- subset(data, select = c(AGE, HOMEKIDS, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, TIF,
                                   CLM_FREQ, MVR_PTS, CAR_AGE), na.rm = TRUE)
summary(numeric)
c <- cor(numeric)
corrplot(c, method = "square")

```


## 5: Fitting Classification Trees on Training Data

```{r, Create a different dataset and then create classification Trees }
data2 = data[2:27]

#summary(data2)
#str(data2)

#Income Initial Test
attach(data2)
NewClaim = ifelse(INCOME <= 100000, "No", "Yes")
NewClaim = as.factor(NewClaim)
data2 = data.frame(data2, NewClaim)
tree.data1 = tree(NewClaim~.-INCOME, data2)
summary(tree.data1)
plot(tree.data1)
text(tree.data1, pretty = 0)

#Involved in an Old Claim
#attach(data2)
NewClaim2 = ifelse(OLDCLAIM >= 5000, "No", "Yes")
NewClaim2 = as.factor(NewClaim2)
data2 = data.frame(data2, NewClaim2)
tree.data2 = tree(NewClaim2~.-OLDCLAIM, data2)
summary(tree.data2)
plot(tree.data2)
text(tree.data2, pretty = 0)

#Age of Car
NewClaim3 = ifelse(CAR_AGE >= 5, "No", "Yes")
NewClaim3 = as.factor(NewClaim3)
data2 = data.frame(data2, NewClaim3)
tree.data3 = tree(NewClaim3~.-CAR_AGE, data2)
summary(tree.data3)
plot(tree.data3)
text(tree.data3, pretty = 0)

set.seed(2)
train=sample(1:nrow(data2), 2000)
data2.test=data2[-train,]
NewClaim3.test=NewClaim3[-train]
tree.data3=tree(NewClaim3~.-CAR_AGE,data2,subset=train)
tree.pred=predict(tree.data3,data2.test,type="class")
table(tree.pred,NewClaim3.test)


#Fitting Regression Trees (Travel Time)
set.seed(1)
train = sample(1:nrow(data2), nrow(data2)/10)
tree.fitreg=tree(TRAVTIME~.,data2,subset=train)
summary(tree.fitreg)
plot(tree.fitreg)
text(tree.fitreg,pretty=0)
cv.data2=cv.tree(tree.fitreg)
plot(cv.data2$size,cv.data2$dev,type='b')
prune.data2=prune.tree(tree.fitreg,best=5)
plot(prune.data2)
text(prune.data2,pretty=0)
yhat=predict(tree.fitreg,newdata=data2[-train,])
fitdata1.test=data2[-train,"TRAVTIME"]
plot(yhat,fitdata1.test)
abline(0,1)
mean((yhat-fitdata1.test)^2)

#Time in Force
set.seed(1)
train2 = sample(1:nrow(data2), nrow(data2)/15)
tree.fitreg2=tree(TIF~.,data2,subset=train2)
summary(tree.fitreg2)
plot(tree.fitreg2)
text(tree.fitreg2,pretty=0)
cv.data2=cv.tree(tree.fitreg2)
plot(cv.data2$k,cv.data2$dev,type='b')
prune.data3=prune.tree(tree.fitreg2,best=5)
plot(prune.data3)
text(prune.data3,pretty=0)
yhat=predict(tree.fitreg2,newdata=data2[-train2,])
fitdata2.test=data2[-train2,"TIF"]
plot(yhat,fitdata2.test)
abline(0,1)
mean((yhat-fitdata2.test)^2)


#Bagging and Random Forests
set.seed(1)
bag.fitreg2=randomForest(TIF~.,data=data2,subset=train,mtry=13,importance=TRUE)
bag.fitreg2
yhat.bag = predict(bag.fitreg2,newdata=data2[-train2,])
plot(yhat.bag, fitdata2.test)
abline(0,1)
mean((yhat.bag-fitdata2.test)^2)
bag.fitreg2=randomForest(TIF~.,data=data2,subset=train2,mtry=13,ntree=25)
yhat.bag = predict(bag.fitreg2,newdata=data2[-train2,])
mean((yhat.bag-fitdata2.test)^2)
set.seed(1)
rf.fitreg2=randomForest(TIF~.,data=data2,subset=train2,mtry=6,importance=TRUE)
yhat.rf = predict(rf.fitreg2,newdata=data2[-train2,])
mean((yhat.rf-fitdata2.test)^2)
importance(rf.fitreg2)
varImpPlot(rf.fitreg2)

# Boosting
data3 = (data2[2:24])
set.seed(1)
boost.data3=gbm(YOJ~.,data=data3[train,],distribution="gaussian",n.trees=5000,interaction.depth=4)
summary(boost.data3)
par(mfrow=c(1,2))
plot(boost.data3,i="TIF")
plot(boost.data3,i="MVR_PTS")
yhat.boost=predict(boost.data3,newdata=data2[-train,],n.trees=5000)
yhat.boost
mean((yhat.boost-fitdata2.test)^2)
boost.data3=gbm(CAR_AGE~.,data=data3[train2,],distribution="gaussian",n.trees=5000,interaction.depth=4,shrinkage=0.2,verbose=F)
yhat.boost=predict(boost.data3,newdata=data3[-train,],n.trees=5000)
mean((yhat.boost-fitdata2.test)^2)


```

## Summary Over Classification Trees


I did notice something that was interesting when creating the various classification trees that I didn't expect when I first looked at the dataset.  When I was looking at the bluebook value, income, car age and job I didn't really figure how those values could be correlated together but after reviewing thata data more, it kinda made sense.  If you are in an auto accident, the value of your car is determined by the insurance company based on the bluebook value and how much you would receive from an accident is based on several factors.  Some of these factors include your age (being a male less than 25 means more risk, so the premiums are usually higher) the amount of income you have (higher income leads to lower rates typically) and finally how old the vehicle is compared to similar types.  So for an example, if you are a college student with minimum income while going to school full-time and get into an accident, you will probably create a claim and try to get as much money as possible because that vehicle could be your only means of transportation to and from school or even work.  Now factor that same scenario into a family with one person attending school and it changes the data slightly but enough to understand how these decision trees can impact whether a person will submit a claim for an accident or not.  The lowest mean value I received was 17.67557 from a random forest tree and I believe that would be the optimal model to use for the target amount value of 1515 that is exported in the excel worksheet.



## 6:  Model Development:


```{r, Model Development for TARGET_FLAG}

#Remove Homekids, RedCar, Car Age, Square Root of TIF
Model1 <- glm(TARGET_FLAG ~ sqrt(SQRT_BLUEBOOK) + sqrt(SQRT_TRAVTIME) + KIDSDRIV + URBANICITY + sqrt(YOJ) +
                sqrt(CLM_FREQ) + REVOKED + MVR_PTS + sqrt(TIF) + EDUCATION_bin + MSTATUS + PARENT1 + 
                CAR_USE + CAR_TYPE + JOB + INCOME_bin + sqrt(HOME_VAL), 
              data = data, family = binomial())
summary(Model1)
data$Model1Prediction <- predict(Model1, type = "response")

####### TESTING AREA
##install.packages("caret") # run install only if you've never installed it before
#library(caret) 
#fit<-glm(TARGET_FLAG ~ sqrt(BLUEBOOK) + sqrt(TRAVTIME) + KIDSDRIV + SEX + URBANICITY + 
#              CLM_FREQ + REVOKED + MVR_PTS + TIF + EDUCATION + MSTATUS + PARENT1 + 
#              CAR_USE + CAR_TYPE + YOJ + JOB + INCOME_bin + sqrt(HOME_VAL), 
#            data = data, family = binomial())
#varImp(fit, scale = FALSE)
#######

#Removing Bluebook
Model2 <- glm(TARGET_FLAG ~ AGE + TRAVTIME + KIDSDRIV + SEX +  URBANICITY +
                CLM_FREQ + REVOKED + MVR_PTS + TIF + EDUCATION + MSTATUS + PARENT1 + CAR_USE + CAR_TYPE + YOJ + JOB + 
                HOME_VAL,
                data = data, family = binomial())
summary(Model2)
data$Model2Prediction <- predict(Model2, type = "response")

Model3 <- glm(TARGET_FLAG ~ AGE + SQRT_TRAVTIME + SQRT_BLUEBOOK + DO_KIDS_DRIVE + URBANICITY +
                CLM_FREQ + REVOKED + MVR_PTS + TIF + EDUCATION + MSTATUS + PARENT1 + CAR_USE + CAR_TYPE + JOB + 
                HOME_OWNER,
              data = data, family = binomial())
summary(Model3)
data$Model3Prediction <- predict(Model3, type = "response")

Model4 = glm(formula = TARGET_FLAG ~ KIDSDRIV + log(INCOME + 1) + PARENT1 + 
              log(HOME_VAL + 1) + MSTATUS + EDUCATION + JOB + TRAVTIME + 
               CAR_USE + BLUEBOOK + TIF + CAR_TYPE + OLDCLAIM + CLM_FREQ + 
               REVOKED + MVR_PTS + URBANICITY, family = binomial(link = "logit"), 
               data = data)
summary(Model4)
data$Model4Prediction = predict(Model4, type = "response")

#Model5 = glm(formula = TARGET_FLAG ~., data=data, family = binomial(link="logit"))



#Model6 ADD ADDITIONAL PREDICTOR VARIABLE SO USE ONLY IMPUTED VALUES
#summary(data)
#ZIP_Model<-zeroinfl(TARGET_FLAG ~ sqrt(BLUEBOOK) + sqrt(TRAVTIME) + SEX + URBANICITY +
#                      REVOKED + TIF + EDUCATION + MSTATUS + PARENT1 + 
#                      CAR_USE + CAR_TYPE + JOB + sqrt(HOME_VAL), 
#                    data = data)
#summary(ZIP_Model)

#data$ZIPphat <- predict(ZIP_Model, newdata = data, type = "response")
#AIC(ZIP_Model)


plotROC(actuals = data$TARGET_FLAG, predictedScores = data$Model1Prediction)
plotROC(actuals = data$TARGET_FLAG, predictedScores = data$Model2Prediction)
plotROC(actuals = data$TARGET_FLAG, predictedScores = data$Model3Prediction)
plotROC(actuals = data$TARGET_FLAG, predictedScores = data$Model4Prediction)

```

## 7:Model Selection and Scoring:


```{r, Choosing the best model and assigning a score value to it}

AIC(Model1)
BIC(Model1)
AIC(Model2)
BIC(Model2)
AIC(Model3)
BIC(Model3)
AIC(Model4)
BIC(Model4)
print(-2*logLik(Model1, REML = TRUE))
print(-2*logLik(Model2, REML = TRUE))
print(-2*logLik(Model3, REML = TRUE))
print(-2*logLik(Model4, REML = TRUE))
ks_stat(actuals=data$TARGET_FLAG, predictedScores=data$Model1Prediction)
ks_stat(actuals=data$TARGET_FLAG, predictedScores=data$Model2Prediction)
ks_stat(actuals=data$TARGET_FLAG, predictedScores=data$Model3Prediction)
ks_stat(actuals=data$TARGET_FLAG, predictedScores=data$Model4Prediction)

# We'll choose Model 1 as the AUROC is .8155 and here are its coefficients
coef(Model1)

#### Part 5:  Score Model on Test Data set and output csv file

# Again, double-checking to make sure we don't have any NA's in our Test Data Set
summary(test)

```

##  STAND ALONE SCORING PROGRAM:


```{r, Model coefficients used to create P_TARGET_FLAG}
test$P_TARGET_FLAG <- predict(Model1, newdata = test, type = "response")

#Prediction File and export to excel
prediction <- test[c("INDEX","P_TARGET_FLAG")]
write.csv(prediction, file = "write_final.csv")


```

## Summary of Results and Method:

There's something that I truly find fascinating about making a model a little bit better and spending additional time to find out how the model behaves with various inputs and outputs.  I'm not a pro at insurance claims at all but from this data set, I can see some similarities in how rates are achieved based upon previous data and where they can increase rates for the insurance factors.  When I did the various classification trees, it gave me some additional factors to look at while examining my model.  I had a slight decrease in my average value from my previous one and used additional factors to determine how to analyze the data.  I think if given the chance, I would start completely over and reach out to an insurance agent and just ask them general questions about how factors are determined in making quotes for various people in different regions.  The next thing I would like at is which states have higher insurance rates and see if the population size has a factor in determining how their rates are adjusted to the urban or rural areas.  Then I would start determine how safety values of the vehicles play into the models.  I would then create various models but keep the same scenarios and see if my accuracy rate is still good while examining the additional ones.
